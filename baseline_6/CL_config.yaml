# General
device: "cpu"

# Dataset
# CIFAR 10 settings
dataset: "CIFAR10"
num_classes: 10
num_tasks: 5 # 2 classes per task

# CIFAR 100 settings
# datset: "cifar100"
# num_classes: 100
# num_tasks: 10 # 2 classes per task

# Paths
backbone_path: "models/quicknet_tinyimagenet_bestmodel.pth"
model_folder: "models"

# Training
batch_size:
  train: 64
  test: 1000
replay_buffer_size: 2000 # Increased from 1000 to 2000, may go back on this
replay_batch: 80
live_batch: 40
epochs: 3

alpha: 0.7
# If α is close to 1, mostly keep the old bank and change it slowly
# If α is close to 0, you mostly take the new weights
learning_rate: 0.001 # lower to match paper

# Continual Learning Strategies
CWR: False # Class-wise rebalancing
EWC: False # Elastic Weight Consolidation
AR1: False # Adaptive Regularization

# EWC parameters
ewc_lambda: 50.0 # Reduced from 100.0 to 50.0 for less aggressive regularization
ewc_fisher_samples: 100

# AR1 parameters
ar1_lambda: 0.005 # Reduced from 0.01 to 0.005 for less aggressive regularization
ar1_alpha: 0.3 # Reduced from 0.5 to 0.3 for less aggressive regularization

# Trainable layers configuration
trainable_layers: "last_k" # Options: "classifier", "last_k", "all"
k_layers: 2
# Model
backbone: "quicknet"

# WandB
wandb_activate: False
project: "Master's Thesis"
