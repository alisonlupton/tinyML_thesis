# Implementation of BNN paper

Using CIFAR10 and CIFAR100 dataset
backbone is quicknet, but I should experiment with more modern ones later

Prefix (frozen): binary convolutions/activations; outputs ±1 LR maps.
Replay memory: store those maps as int8 (values −1/ +1). Later you can bit‑pack to 1‑bit.
Tail + classifier (trainable): keep FP32 for training stability (as you wanted).
