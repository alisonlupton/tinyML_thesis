# First implementation of a CORRECT continual learning pipeline
Train backbone on KMNIST then attatched an adapter head and performed continual learning on MNIST.
Decent accuracy and forgetting results achieved, but forgetting can definetely be improved. 
Next step is to measure RAM and FLASH more directly, so that more interesting implementations can be added, and I also need to see what is realistic for a train_mb size.
Furthermore, we need to test more complex datasets, and also create baseline comparisions of trying out different
datasets for the frozen backbones. 